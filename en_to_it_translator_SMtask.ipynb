{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Italian Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment implements Helsinki-NLP's translator model to translate an input in English to Italian Output. Functions from the transformers library are called to develop a pipeline for the specific model chosen and to tokenize the text input taken from the user before running it in the model. The model provided is pretrained and fine tuned and hence further preprocessing was not required. Once the model checkpoint is stored in a variable, the Translator pipeline when called provides a simplified method of inferring from models via APIs dedicated to the tasks. Once tokenization is complete and the pipeline is loaded, after user input the pipeline is called and the translation takes place hence being complete.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to the model implemented: https://huggingface.co/Helsinki-NLP/opus-mt-en-it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pipeline function from the transformers library to access pre-trained models for inferences\n",
    "# AutoTokenizer function is used to tokenize the inputs and targets of the dataset to help the system understand\n",
    "# importing torch library to return tensors\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization and pipeline loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The specific model checkpoint is called and stored\n",
    "model_name=\"Helsinki-NLP/opus-mt-en-it\"\n",
    "#the string is tokenised/split into sub-strings to prepare the input for the model's interpretation\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name, return_tensors=\"pt\")\n",
    "#using the translation pipeline for our specific model\n",
    "classifier=pipeline(\"translation\",model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Input and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Ciao sono uno studente di informatica in India. La mia università è NMIMS MPSTME. In che università vai?'}]\n"
     ]
    }
   ],
   "source": [
    "#taking input from user\n",
    "enString=input(\"Input text to translate \\n\")\n",
    "#calling classifier- the translation pipeline\n",
    "res=classifier(enString)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12ebbf8cc1c2f1e1058acedf029daf8ced5f833283ea2e357e9b000e35da47d7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
